#+OPTIONS: toc:nil
#+PROPERTY: header-args:jupyter-julia :session DevNotes :kernel julia :eval no-export :async yes :exports both

:TEX_MATHJAX_SETUP:
#+LATEX_COMPILER: lualatex

# #+LATEX_HEADER: \usepackage[margin=48bp,paperwidth=7in,paperheight=10in]{geometry}
#+LATEX_HEADER: \AtBeginDocument{\renewcommand*{\vec}{\symbf}}
#+LATEX_HEADER: \AtBeginDocument{\newcommand*{\uvec}[1]{\hat{\vec #1}}}
#+LATEX_HEADER: \newcommand*{\norm}[1]{|#1|}
#+LATEX_HEADER: \newcommand*{\ten}{\symbfsf}
#+LATEX_HEADER: \newcommand*{\pd}{\partial}
#+LATEX_HEADER: \newcommand*{\grad}{\vec\nabla}
#+LATEX_HEADER: \newcommand*\dd{\mathop{}\!\mathrm{d}}
#+LATEX_HEADER: \newcommand*\Reals{\symbb R}
#+LATEX_HEADER: \DeclareMathOperator{\supp}{supp}

#+LATEX_HEADER: \setmainfont{STIX Two Text}
#+LATEX_HEADER: \setmathfont{STIX Two Math}
#+LATEX_HEADER: \setmonofont{JuliaMono}

#+LATEX_HEADER: \setlength{\parindent}{0pt}
#+LATEX_HEADER: \setlength{\parskip}{\medskipamount}

# Macros for MathJAX
#+begin_export html
\(
\newcommand{\pd}{\partial}
\renewcommand{\vec}{\boldsymbol}
\newcommand{\uvec}[1]{\hat{\vec #1}}
\renewcommand{\ten}[1]{\boldsymbol{\mathsf{#1}}}
\newcommand\dd{\mathop{}\!\mathrm{d}}
\newcommand{\grad}{\vec\nabla}
\newcommand{\symbb}{\mathbb}
\newcommand{\Reals}{\symbb R}
\newcommand\NRe{\mathinner{Re}}
\newcommand{\norm}[1]{|#1|}
\DeclareMathOperator{\supp}{supp}
\)
#+end_export
:END:

:JULIA_SETUP:
#+begin_src jupyter-julia :results silent :exports none
using LinearAlgebra
using Static
using ArrayInterface: ArrayInterface as Arr
using StaticArrays
using StaticArrays: sacollect
using MultilinearMaps
import MultilinearMaps as MM

using Test
using BenchmarkTools

if !@isdefined(BenchmarkTools)
    macro btime(args...)
        :(println("<benchmark skipped>"))
    end
    macro benchmark(args...)
        :(println("<benchmark skipped>"))
    end
end

showit(x) = (show(stdout, "text/plain", x); println())
#+end_src
:END:


#+TITLE: ~MultilinearMaps~


* Introduction

Multilinear maps (see [[wikipedia:Multilinear_map][Wikipedia]] and [[https://www.isical.ac.in/~arnabc/q/tensor.html][this page]]) are functions of \(K\) vectors (potentially belonging to difference vector spaces) and map them to vectors in an "output" vector space \(W\).
Thus, a multilinear map is a function
\begin{equation*}
f : V_1 ‚ãØ V_K ‚Üí W
\end{equation*}
If the codomain of \(f\) is a field of scalars, then we call \(f\) a [[wikipedia:Multilinear_form][multilinear form]].
If \(M\) of the \(V_1, ‚ãØ, V_K\) are a vector space \(V\) and the remaining \(N\) are the dual space of \(V\), \(V^*\), then \(f\) is called a \((M,N)\)-tensor.
A familiar example of a multilinear map (a multilinear form in this case) is the standard inner product (dot product) of vectors, which is a bilinear form (also called a 2-linear form or a 2nd order multilinear form).
It takes two vectors and produces a scalar.

The most general form of a multilinear map is
\begin{equation*}
  f(v_1, ‚ãØ, v_K) = \sum_{i_1}^{D_1} ‚ãØ \sum_{i_K}^{D_K} \vec A_{i_1 ‚ãØ i_K} v_{1 i_1} ‚ãØ v_{K i_K}
\end{equation*}
where \(D_j\) gives the dimension of the vector space to which \(\vec v_j\) belongs.
Thus, \(f\) can be represented by an \(K\)-dimensional array of components.
For example, for the inner product form, \(\uvec e_i ‚ãÖ \uvec e_j \) corresponds to the Kronecker delta \(Œ¥_{ij}\).
However, representing multilinear maps as ~function~‚Äãs on vectors in computational code is useful, especially if \(f\) has special structure.
(For instance, computing an inner product by naively multiplying by the identity matrix by \(v_1\) on the left and \(v_2\) on the right is not very efficient.)

Here is another example of a 4-linear form, which takes four vectors and produces a scalar
#+begin_src jupyter-julia :results silent :tangle examples.jl
@inline _skew(v1, v2, v3, v4) = ((v1‚ãÖv3)*(v2‚ãÖv4) - (v1‚ãÖv4)*(v2‚ãÖv3))
@inline _skew(vs::NTuple{4}) = _skew(vs...)
#+end_src
and has components \(Œ¥_{ik} Œ¥_{jl} - Œ¥_{il} Œ¥_{jk}\).

** Functions on indices

The following functions are similar to ~_inner~ and ~_skew~, but are directly functions of indices rather than vectors.  They are essentially equivalent if one restricts attention to arguments ~v1, ‚ãØ, vN~ being one of the standard unit vectors \(\uvec e_1 ‚ãØ \uvec e_N\).
We can use them to directly compute the components of each form in a way that is efficient over taking dot products of (over the product space of) the standard unit vectors in \(\Reals^D\).
#+begin_src jupyter-julia :results silent :tangle examples.jl
# The Kronecker delta, Œ¥_{ij}, as a function of indices
inner_ixfn(i, j) = (i==j)
@inline inner_ixfn(args::Dims{2}) = inner_ixfn(args...)
@inline inner_ixfn(I::CartesianIndex{2}) = inner_ixfn(Tuple(I)...)

# A 4th order isotropic tensor, Œ¥_{ik} Œ¥_{jl} - Œ¥_{il} Œ¥_{jk}
skew_ixfn(i, j, k, l) = (i==k) * (j==l) - (i==l) * (j==k)
@inline skew_ixfn(args::Dims{4}) = skew_ixfn(args...)
@inline skew_ixfn(I::CartesianIndex{4}) = skew_ixfn(Tuple(I)...)
#+end_src

We can loop over functions like these to fill up an array of tensor components.
(In [[file:src/util.jl]], we define ~fillfn!~, which has this job.)


#+begin_src jupyter-julia
let # SDims = NTuple{4,3}
    # dims = fieldtypes(SDims)
    # ixfn = skew_ixfn
    # T = eltype(ixfn(ntuple(_ -> 1, Val(fieldcount(SDims)))))

    println("  Iteration over `CartesianIndices`")
    out1 = @btime(
        MM.fillfn_cartesianindices!(A, $skew_ixfn),
        setup=(A = MArray{NTuple{4,3},Int}(undef))
    )
    println("  Using `Base.Cartesian`")
    out2 = @btime(
        MM.fillfn!(A, $skew_ixfn),
        setup=(A = MArray{NTuple{4,3},Int}(undef))
    )
    println("`SArray` via `sacollect`")
    out3 = @btime(
        sacollect(SArray{NTuple{4,3}}, $skew_ixfn(I) for I ‚àà Is),
        setup=(Is = CartesianIndices(ntuple(_ -> SOneTo(3), Val(4))))
    )

    @assert out1 == out2 == out3
    out3
end
#+end_src

Use of ~sacollect~ is most efficient because it effectively unrolls all the loops.
However, using approaches with looping might be beneficial in cases where loop unrolling would create too much work for the compiler.
We will try to sacrifice as little performance over these "baseline" functions on indices as possible in our implementation below.


* Unit vectors and indices

There is really no distinction between functions on indices, which give the components of a tensor, and multilinear forms on the standard unit vectors because the index \(i\) directly maps over to the unit vector \(e_i\) pointing in the \(i\)th direction.
We therefore define ~StdUnitVector{D}(d::Int)~ (see [[file:src/stdbasis.jl][stdbasis.jl]]) to represent a standard unit vector that points in the ~d~-th direction of a ~D~-dimensional vector space.

Some notes about the implementation:
- the dot product (~LinearAlgebra.dot~) of two ~StdUnitVector~‚Äãs amounts to checking if they point in the same direction
- the dot product of a ~StdUnitVector~ with a "regular" vector just performs indexing
- the dot product of any other kinds of "regular" vectors just falls back to the usual algorithm given by ~LinearAlgebra.dot~

Now, if we evaluate ~dot~ where the operands are pairs of ~StdUnitVector{N}~‚Äãs, we really just have a function that tests whether the ~direction~ of each vector is the same.
For example, the dot product between two unit vectors, ~[1, 0, 0]~ and ~[0, 0, 1]~, is reduced to testing whether ~1==3~, which evaluates to ~false == 0~.

Below, we construct a \(3√ó3\) identity matrix using ~StdUnitVector~‚Äãs.
#+begin_src jupyter-julia :results scalar
let sbasis = StdBasis{3}(Real)
    [e1 ‚ãÖ e2 for e1 ‚àà sbasis, e2 ‚àà sbasis]
end
#+end_src

Note that the matrix elements are of type ~Bool~ values is created ~StdUnitVector~.
This is a direct result of the boolean tests performed for each element of the matrix.
Indeed, the code above is equivalent to
#+begin_src julia :exports code :eval no
[i == j for j ‚àà 1:3, i ‚àà 1:3]
#+end_src

** Tests

#+begin_src jupyter-julia
using Test

@testset "Unit Vectors" begin
    e = StdUnitVector
    @testset "Construction" begin
        @test Arr.size(e{2}(1)) isa MM.SizeS{1}
        @test length(e{2}(1)) == only(size(e{2}(1)))
        @test_throws DomainError e{2}(3)
        @test_throws DomainError e{1}(0)
        @test only(e{1}(1))
    end
    @testset "Equality" begin
        @test e{2}(1) == e{2}(1)
        @test e{2}(1) !== e{2}(2)
        @test e{2}(1) !== e{3}(1)
        @test e{2}(1) == Bool[true, false]
        @test e{2}(1) !== Bool[true, false, false]
    end
    @testset "Dot product" begin
        @test @inferred e{1}(1) ‚ãÖ e{1}(1)
        @test e{2}(1) ‚ãÖ e{2}(1)
        @test !(e{2}(1) ‚ãÖ e{2}(2))
        @test !(e{2}(2) ‚ãÖ e{2}(1))
        @test e{2}(1) ‚ãÖ [1,2] == [1,2] ‚ãÖ e{2}(1) == 1
        @test e{2}(2) ‚ãÖ [1,2] == [1,2] ‚ãÖ e{2}(2) == 2
        @test e{2}(1) ‚ãÖ SVector(1,2) == SVector(1,2) ‚ãÖ e{2}(1) == 1
        @test e{2}(2) ‚ãÖ [1,2] == [1,2] ‚ãÖ e{2}(2) == 2
        @test_throws DimensionMismatch e{2}(1) ‚ãÖ e{1}(1)
        @test_throws DimensionMismatch SVector(1,2) ‚ãÖ e{1}(1)
        @test_throws DimensionMismatch [1,2] ‚ãÖ e{1}(1)
    end
    # Other
    @test @inferred(e{2}(2) + [1,0]) == ones(2)
    @test SVector{2}(e{2}(1) + e{2}(2)) === ones(SVector{2,eltype(true+true)})
    @test_broken SVector(e{2}(1) + e{2}(2)) === ones(SVector{2,eltype(true+true)})
end;
#+end_src

** Performance

When creating a unit vector, one generally wants to validate that its direction is appropriate for the vector space, i.e., ~1 ‚â§ d ‚â§ D~.
Indeed, constructing a two-dimensional unit vector pointing into the third dimension is invalid and will helpfully raise an exception.
#+begin_src jupyter-julia :eval no
StdUnitVector{2}(3)  # raises error
#+end_src

Like bounds checking of array access, this comes with some overhead.
However, we may want to elide such checks if we are confident that the unit vectors we construct are valid.
Therefore, we provide "unsafe construction" of unit vectors to elide the dimensionality check.
(Warning: doing so could lead to strange difficult-to-debug behavior; see below.)
#+begin_src jupyter-julia
collect(StdUnitVector{2}(MM.UNSAFE, 3))  # 3 not less than 2!
#+end_src

We can check for any overhead of the ~UNSAFE~ method to direct computation on the indices, and there seems to be none.
#+begin_src jupyter-julia :results scalar
using MultilinearMaps: Safety, SAFE, UNSAFE

@inline inds2uvecs(safety::S, inds::Vararg{Int}) where {S<:Safety} = map(i -> StdUnitVector{3}(safety, i), inds)
@inline inds2uvecs(safety::S) where {S<:Safety} = (inds...) -> inds2uvecs(safety, inds...)
# @inline inds2uvecs(I::CartesianIndex) = map(StdUnitVector{3}, Tuple(I))
println("Function of indices")
out_ixfn = @btime MM.fillfn!(A, skew_ixfn) setup=(A = MArray{NTuple{4,3},Int64}(undef))
println("SAFE unit vectors (validity checked)")
out_safe = @btime(MM.fillfn!(A, _skew ‚àò inds2uvecs(SAFE)),
                  setup=(A = MArray{NTuple{4,3},Int64}(undef)))
println("UNSAFE unit vectors (no validity check)")
out_unsafe = @btime(MM.fillfn!(A, _skew ‚àò inds2uvecs(UNSAFE)),
                    setup=(A = MArray{NTuple{4,3},Int64}(undef)))
@assert out_ixfn == out_safe == out_unsafe
#+end_src

Interestingly, completely explicit loops are little faster, but why?

#+begin_src jupyter-julia
@btime(
    begin for l ‚àà axes(A,4), k ‚àà axes(A,3), j ‚àà axes(A,2), i ‚àà axes(A,1)
        @inbounds A[i,j,k,l] = _skew(StdUnitVector{3}(UNSAFE, i), StdUnitVector{3}(UNSAFE, j),
                                     StdUnitVector{3}(UNSAFE, k), StdUnitVector{3}(UNSAFE, l))
    end
    A
    end,
    setup=(A = MArray{NTuple{4,3}, Int64}(undef))
);
#+end_src


* Multilinear maps

In [[file:src/MultilinearMaps.jl][MultilinearMaps.jl]], we define a callable type ~MultilinearMap~ whose instances represent multilinear forms.
A ~MultilinearMap~ is constructed by passing an "implementation" function like ~LinearAlgebra.dot~ or ~_skew~.
We'll restrict our attention to the case where the vectors operated on by a given ~MultilinearMap~ are of known spatial dimension (~length~), usually being between 1--4 and most commonly 2 or 3.
Thus, we represent such vectors using types from ~StaticArrays~ for efficiency.

Let's define a few ~MultilinearMaps~ (in three dimensions) to work on below.
#+begin_src jupyter-julia
const eÃÇ = StdUnitVector  # For convenience
_just_true() = true
const solo = MultilinearForm{0}(_just_true)
const inner = MultilinearForm{2,3}(dot)
const skew = MultilinearForm{4,3}(_skew)
#+end_src

Check that things work correctly.

#+begin_src jupyter-julia
using Test

@testset "Multilinear Form -> Scalar" begin
    u = StdUnitVector{2}(1) # SVector(1., 0.)
    v = StdUnitVector{2}(2) # SVector(0., 1.)
    solo = @inferred MultilinearForm{0,3}(_just_true)
    inner = @inferred MultilinearForm{2,2}(dot)
    skew = @inferred MultilinearForm{4,2}(_skew)
    @test solo() == true
    @test_throws MethodError solo(u)
    @test inner(u,u) == 1
    @test inner(u,v) == 0
    @test inner(v,u) == 0
    @test_throws MethodError inner(u)
    @test skew(u,u,v,v) == 0
    @test skew(u,v,u,v) == 1
    @test skew(u,v,v,u) == -1
end;
#+end_src

Check that things work efficiently (no allocations, e.g.).

#+begin_src jupyter-julia :results scalar
using BenchmarkTools
using Test

let u = SVector(1, 0, 0), v = SVector{3}(0, 1, 0)
    inner = MultilinearMap{(3,3)}(dot)
    skew = MultilinearForm{4,3}(_skew)
    println("Contraction, map with argument dimensions $(size(inner))")
    @assert 1 == @btime($inner($(u,u)...))
    println("Contraction, map with argument dimensions $(size(skew))")
    @assert 1 == @btime($skew($(u,v,u,v)...))
end
#+end_src

** Contraction

We can think of a ~MultilinearMap~ applied to only ~N~ of its ~K~ arguments as a similar multilinear map of order ~K-N~.
We call such a multilinear form "contracted", which is implemented by ~ContractedMultilinearForm~.
We also use the ~Colon~ (~:~) to indicate a "free index" of the tensor / form.
When a ~MultilinearForm~ is ~collect~‚Äãed into an array, the ~:~ indicates slots/indices which should be looped over for all the unit vectors to generate numerical components.

#+begin_src jupyter-julia :results scalar
let basis = StdBasis{3}(Real)
    e2 = basis[2]
    x = inner(:, e2)
    [x(e) for e ‚àà basis]
end
#+end_src


Some tests:

#+begin_src jupyter-julia
@testset "Multilinear Form -> Contracted Form" begin
    let
        u = StdUnitVector{2}(1) # SVector(1., 0.)
        v = StdUnitVector{2}(2) # SVector(0., 1.)
        inner = @inferred MultilinearForm{2,2}(dot)
        @test_throws MethodError inner(:,:,:)
        @test_throws MethodError inner(:)
        @test inner(:,:) === inner
        @inferred inner(u,:)
        @test 1 == inner(u,u) == @inferred inner(u,:)(u) == @inferred inner(:,u)(u)
    end
    let (u,v,w,x) = ntuple(_ -> rand(SVector{3,Float64}), Val(4))
        inner = @inferred MultilinearForm{2,3}(dot)
        skew = @inferred MultilinearForm{4,3}(_skew)
        @inferred skew(u,v,w,:)
        @inferred skew(u,v,w,:)(x)
        @test inner(u,v) == inner(u,:)(v) == inner(:,u)(v) == inner(:,:)(u,v)
        @test skew(u,v,w,x) ‚âà skew(u,v,w,:)(x) ‚âà skew(u,v,:,:)(w,x) ‚âà
            skew(u,:,:,:)(v,w,x) ‚âà skew(:,v,w,x)(u)
    end
end;
#+end_src

We might want more functionality in the future, like the ability to permute the argument order of the vector arguments.
We leave that to later work.


* Interfaces for iteration, indexing, etc.

We can now produce an identity matrix as follows by using ~inner~, defined above, and ~StdUnitVector~.
#+begin_src jupyter-julia
@btime [inner(e1, e2) for e1 ‚àà sb, e2 ‚àà sb] setup=begin
    sb = StdBasis{3}(Real)
end
#+end_src

However, much convenience is provided by implementing the [[https://docs.julialang.org/en/v1/manual/interfaces/][iteration and indexing interfaces]] for ~MultilinearForm~‚Äãs.
This will allow us to "collect" a ~MultilinearForm~ into an array container like ~Array~ or ~SArray~ using ~collect~ or ~StaticArrays.sacollect~, respectively.
(Note that we commit some type piracy in doing so.  It would be nice if ~sacollect~ had a generic method that could handle iterators that possessed a ~Size~ trait without having to specify the size in the type ~SA~.  We have hacked that together above, but maybe something like this should be considered for inclusion in ~StaticArrays~ itself.)
Indexing is done by simply converting each index to a corresponding ~StdUnitVector~ like ~mf[i,j,...] = mf(StdUnitVector{3}(i), StdUnitVector{3}(j), ...)~, to provide a convenience shorthand.
The methods necessary to make this work are implemented in [[file:src/MultilinearForms.jl][MultilinearForms.jl]].
There, we also implement methods for ~StaticArrays.similar_type~ and ~Base.similar~ to provide appropriate types to contain components of ~MultilinearForms~.

Note that when ~@inbounds~ is used, unit vectors are unsafely constructed, without checking if their direction is valid for their dimension.

** Indexing

#+begin_src jupyter-julia :results scalar
# MM._getindex(MM.UNSAFE, inner, 1, 1)
@btime inner(eÃÇ{3}(1), eÃÇ{3}(1))
@btime MM._getindex(MM.SAFE, inner, 1, 3)
@btime inner[1,3]
#+end_src


** Iteration and Collection

The identity matrix (~inner~) can now be collected into an array with a single line of code.
#+begin_src jupyter-julia :results scalar
@btime materialize(SArray, Bool, inner)
@btime materialize(SMatrix{3,3}, Bool, inner)
@btime materialize(SMatrix, Bool, inner)  # XXX type stable but bad performace
#+end_src

Since the size of each dimension is usually small and a fixed constant, we integrate with ~StaticArrays~.
#+begin_src jupyter-julia
@testset "StaticArrays traits" begin
    @test StaticArrays.Length(inner) == StaticArrays.Length(3^2)
    @test StaticArrays.Length(skew) == StaticArrays.Length(3^4)
    @test StaticArrays.Size(inner) == StaticArrays.Size(3,3)
    @test StaticArrays.Size(skew) == StaticArrays.Size(3,3,3,3)
end;
#+end_src

We can collect after contraction / "slicing", too.
Let's get a slice or two of the ~skew~ tensor üçï.
#+begin_src jupyter-julia
@testset "More contractions" begin
    skew_components = SArray(skew)  # Materialize the whole tensor
    # Now, slice the component array and compare it to tensor contraction
    # with the unit vectors
    @test SArray(skew(eÃÇ{3}(1), :, eÃÇ{3}(2), :)) == skew_components[1,:,2,:]
    @test SArray(skew(:, :, eÃÇ{3}(3), eÃÇ{3}(2))) == skew_components[:,:,3,2]
end;
#+end_src

Note that components of the tensor the user has not asked for are never computed.

*** Materialization

Create an array of type ~T~ filled with the components of ~f~.

#+begin_src jupyter-julia
@btime materialize!(A, skew) setup=(A = MArray{NTuple{4,3},Int64}(undef));
#+end_src

** Validity & Performance Checks

#+begin_src jupyter-julia :results scalar
let
    solo = MultilinearForm{0}(() -> 1.0)
    inner = MultilinearForm{2,3}(dot)
    skew = MultilinearForm{4,3}(_skew)
    @btime materialize(Scalar, $solo)
    @btime SArray($inner)
    @btime materialize(SArray, $skew#=(:,:,:,:)=#)
end
#+end_src



#+begin_src jupyter-julia
let u = SVector{3}(1:3), v = SVector{3}(3:-1:1)
    @btime SArray(MultilinearForm{4,3}(_skew))
    out1 = @btime SArray(skew)[:,:,3,2]
    out2 = @btime SArray(skew(:,:, eÃÇ{3}(3), eÃÇ{3}(2)))
    @test out1 == out2
end
#+end_src


* Linear Combinations of Multilinear Maps

Multilinear maps form a vector space.
That is, we can take linear combinations of multilinear maps and generally produce another multilinear map.

** Tests

#+begin_src jupyter-julia :results scalar
@testset "Vector Space" begin
    @testset "Equality" begin
        @test inner == inner
        @test inner != skew
        @test skew != inner
    end
    @testset "Scalar Multiples" begin
        @test MM.ScalarMultiple(inner, 0.5) == 0.5 * inner == inner / 2
        @test inner !== inner / 2
        @test MM.ScalarMultiple(inner, 1//2) == inner // 2 == 1//2 * inner
    end
    @testset "Sums" begin
        # Associativity
        @test (inner + inner) + inner == inner + (inner + inner) == inner + inner + inner
        # Can't add maps of unequal sizes (should probably give a more helpful exception)
        @test_throws DimensionMismatch inner + skew
    end;
    @testset "Linear Combinations" begin
        @test all(==(0), skew - skew)
        @test inner + inner == 2 * inner
        @test inner + inner + inner == 2*inner + inner == inner + 2*inner == 3*inner
        @test 2*(skew + skew) / 2 == 2*skew
    end
end;
#+end_src

* More complex (and useful) multilinear forms

** Spherical harmonics

The functions below give the spherical harmonics (the traceless symmetric tensors) on \(\mathbb S^2\).
(/Note, these are great for unit tests!/ Can also check that the results are symmetric and traceless to ensure there is no regression in computing correct results.)

#+begin_src jupyter-julia :results silent :tangle test/harmonics.jl
# Functions that represent (tensor) spherical harmonics
sphharm30(_) = MultilinearForm{0,3}(() -> true)
sphharm31(nÃÇ) = MultilinearForm{1,3}((v) -> nÃÇ‚ãÖv)
sphharm32(nÃÇ) = MultilinearForm{2,3}((v1, v2) -> (nÃÇ‚ãÖv1)*(nÃÇ‚ãÖv2) - (v1‚ãÖv2)/3 )
sphharm33(nÃÇ) = MultilinearForm{3,3}((v1, v2, v3) ->
    (nÃÇ‚ãÖv1)*(nÃÇ‚ãÖv2)*(nÃÇ‚ãÖv3) - ((v1‚ãÖv2)*(nÃÇ‚ãÖv3) + (v3‚ãÖv1)*(nÃÇ‚ãÖv2) + (v2‚ãÖv3)*(nÃÇ‚ãÖv1))/5)
#+end_src

These should be traceless and symmetric when collected into an matrix/array.
#+begin_src jupyter-julia
using Test

"""Test (recursively) if an array is traceless in every pair of indices"""
istraceless(A::AbstractArray{<:Any, 0}, _::Int) = true
istraceless(A::AbstractArray{<:Any, 1}, _::Int) = true
istraceless(A::AbstractArray{<:Any, 2}, _::Int) =
    ‚âà(tr(A), 0, atol=‚àö(eps(eltype(A))))
istraceless(A::AbstractArray, dim::Int) =
    all(istraceless(B) for B in eachslice(A, dims=dim))
    # For dim = 1, does
    # all(‚âà(tr(out[i,:,:]), 0, atol=eps(eltype(out))) for i ‚àà axes(out, 1))
istraceless(A::AbstractArray) = all(istraceless(A, dim) for dim ‚àà 1:ndims(A))

_issymmetric(A::AbstractArray{<:Any, 0}) = true
_issymmetric(A::AbstractArray{<:Any, 1}) = true
_issymmetric(A::AbstractArray{<:Any, 2}) =
    all(‚âà(A[i,j] - A[j,i], 0, atol=‚àö(eps(eltype(A)))) for i ‚àà axes(A,1), j ‚àà axes(A,2))
# _issymmetric(A::AbstractArray, dim) = all(issymmetric(B) for B in eachslice(A, dims=dim))
# _issymmetric(A::AbstractArray) = all(issymmetric(A, dim) for dim in 1:ndims(A))

@testset "Harmonics" begin
    x = normalize(rand(SVector{3,Float64}))
    eÃÇ = StdUnitVector{3}
    @testset "Traceless" begin
        for formfield in (sphharm30, sphharm31, sphharm32, sphharm33)
            form = formfield(x)
            K = ndims(form)
            D = Arr.size(form, 1)
            out = SArray(form)
            @test ndims(out) == K
            @test all(==(D), size(out))
            @test istraceless(out)
        end
    end
    @testset "Symmetric" begin
        @test issymmetric(SArray(sphharm32(x)))
        for i ‚àà 1:3
            @test _issymmetric(SArray(sphharm33(x)(:,:, eÃÇ(i))))
            @test _issymmetric(SArray(sphharm33(x)(:, eÃÇ(i), :)))
            # Needed? I think implied by the previous two
            @test _issymmetric(SArray(sphharm33(x)(eÃÇ(i), :, :)))
        end
    end
end;
#+end_src

Lets check the performance of these functions.

#+begin_src jupyter-julia
using BenchmarkTools, StaticArrays

bmarks = let
    nÃÇ = rand(SVector{3})
    (u, v, w) = ntuple(_ -> round.(normalize(rand(SVector{3})), digits=2), Val(3))

    # fns = (sphharm32 => ((:, :), (:, v), (u, v)),
    #        sphharm33 => ((:, :, :), (:, :, w), (:, v, w), (u, v, w)))

    # b = Vector{BenchmarkTools.Trial}(undef, mapreduce(length ‚àò last, +, fns))

    # i = 0
    # for (fn, args_set) ‚àà fns
    #     println("Evaluating $fn at a random point on the sphere with")
    #     for (n, args) ‚àà enumerate(args_set)
    #         println("$fn(nÃÇ)$args")
    #         b[i+=1] = @benchmark $fn(nÃÇ)($args...) setup=(nÃÇ=normalize(rand(SVector{3, Float64})))
    #         println("  time = ", minimum(b[i].times))
    #     end
    # end

    println("Second order form")
    println("  all components -> 3x3 matrix")
    @btime SArray(sphharm32(nÃÇ[])) setup=(nÃÇ=$(Ref(nÃÇ)))
    println("  single contraction -> length-3 vector  (matrix-vector prodct)")
    @btime SArray(sphharm32(nÃÇ[])(:, v[])) setup=(nÃÇ=$(Ref(nÃÇ)); v=$(Ref(v)))
    println("  double contraction -> scalar  (quadratic form)")
    @btime sphharm32(nÃÇ[])(u[], v[]) setup=(nÃÇ=$(Ref(nÃÇ)); u=$(Ref(u)); v=$(Ref(v)))
    println()

    println("Thrid order form")
    println("  all components -> 3x3x3 array")
    @btime SArray(sphharm33(nÃÇ[])(:, :, :)) setup=(nÃÇ=$(Ref(nÃÇ));)
    println("  single contraction -> 3x3 matrix")
    @btime SArray(sphharm33(nÃÇ[])(:, :, u[])) setup=(nÃÇ=$(Ref(nÃÇ)); u=$(Ref(u)))
    println("  double contraction -> length-3 vector")
    @btime SArray(sphharm33(nÃÇ[])(:, u[], v[])) setup=(nÃÇ=$(Ref(nÃÇ)); u=$(Ref(u)); v=$(Ref(v)))
    println("  full contraction -> scalar")
    @btime sphharm33(nÃÇ[])(u[], v[], w[]) setup=(nÃÇ=$(Ref(nÃÇ)); u=$(Ref(u)); v=$(Ref(v)); w=$(Ref(w)))
end;
#+end_src

It seems to be as good as we can expect.

* Stokes-flow hydrodynamics

** Stokes multipoles

How about the all-important (to me) Stokeslet tensor \(S\) in three dimensions?  In the usual index notation,
\[ 8œÄ S_{ij}(\vec x) = \frac{Œ¥_{ij}}{r} + \frac{x_i x_j }{r^3}, \]
where \(\vec x\) is the position vector and \(r = |\vec x|\).
We can also write the Stokeslet at each point as a multilinear function
\[ 8œÄ \left. S(\uvec e, \vec f) \right|_{x} = \frac{\uvec e ‚ãÖ \vec f}{r} + \frac{(\uvec e ‚ãÖ \vec x)(\vec f ‚ãÖ \vec x)}{r^3}, \]
where \(\uvec e\) is a unit vector (in an arbitrary direction) representing the direction of the flow speed that is computed and \(f\) is the point force at the origin.

Thus, we can get the \(ij\)-th component as \(S_{ij}(x) = \left. S(\hat{\vec e}_i, \hat{\vec e}_j) \right|_{x}\).

#+begin_src jupyter-julia
function stokeslet(x)
    # For efficiency, pre-compute quantities depending on position (x) alone.
    # We also reduce division as much as possible in favor multiplication
    # (faster).
    recip_r = inv(norm(x))
    xÃÇ = x * recip_r
    prefactor = recip_r / 8œÄ

    # Here is the "implementation" function
    _stokeslet(e, f) = ((e‚ãÖf) + (e‚ãÖxÃÇ)*(xÃÇ‚ãÖf)) * prefactor
    # (Compare to the usual index notation.)

    # Now make it a second order multilinear form in three dimensions
    return MultilinearForm{2,3}(_stokeslet)
end
@btime SArray(stokeslet(x)) setup=(x=SVector{3,Float64}(1.,2,3))
#+end_src

We are left with a matrix of the components of our favorite (symmetric) tensor.
We can also contract the Stokeslet with a (force) vector to give the Stokeslet velocity field at a given point.
#+begin_src jupyter-julia
@btime SArray(stokeslet(x)(:,f)) setup=begin
    x = SVector{3,Float64}(1,2,3) # Position vector
    f = SVector{3,Float64}(3,2,1) # Force vector
end
#+end_src

#+begin_src jupyter-julia
let x = normalize(rand(SVector{3}))
    f = normalize(rand(SVector{3}))
    stokeslet(x)(:,f)                   |> showit ‚àò SArray
    (stokeslet(x) - stokeslet(x))(:,f)  |> showit ‚àò SArray
end
#+end_src

If we use a ~StdUnitVector~ as one of the vectors, we should get the corresponding column/row of the Stokeslet as a matrix.
#+begin_src jupyter-julia
@btime SArray(stokeslet(x)(:,f)) setup=begin
    x = SVector{3,Float64}(1,2,3)
    f = eÃÇ{3}(2)  # take second row/col
end
#+end_src

Computational cost is reduced if you contract the Stokeslet with a vector because the "full" matrix is never formed.
Contraction with a unit vector is even cheaper, since it is equivalent to forming just one row of the Stokeslet.
We can even compute just a single component of the velocity as a scalar.
#+begin_src jupyter-julia
@btime stokeslet(x)(e,f) setup=begin
    x = SVector{3,Float64}(1,2,3)
    # Direction of flow diagonally on xy plane
    e = normalize(SVector{3,Float64}(1,1,0))
    f = SVector{3,Float64}(3,2,1)
end
#+end_src

As it is possible to pick out a row/column, it is also possible to pick out just one component of the Stokeslet by feeding it two ~StdUnitVector~‚Äãs.
#+begin_src jupyter-julia
@btime stokeslet(x)(e,f) setup=begin
    x = SVector{3,Float64}(1,2,3)
    e = eÃÇ{3}(1)
    f = eÃÇ{3}(2)
end
#+end_src

Note that, in all cases, most of the computational cost of evaluating a Stokeslet is actually due to computation of the spatial dependence (taking ~norm(x)~, etc.), though this can be somewhat reduced by annotating the definition of ~stokeslet~ with ~@fastmath~.
#+begin_src jupyter-julia
@btime stokeslet(x) setup=(x = SVector{3}(1., 2., 3.));
#+end_src

Without all this machinery, the Stokeslet is not too hard to express using facilities from ~Base~ and ~LinearAlgebra~.
#+begin_src jupyter-julia
function stokeslet2(x)
    recip_r = inv(norm(x))
    xÃÇ = x * recip_r
    prefactor = recip_r / 8œÄ
    (SMatrix{3,3,Float64}(I) .+ xÃÇ .* xÃÇ') .* prefactor
end
@btime stokeslet2(SVector(1.,2,3))
#+end_src

Our code is actually a hair faster it seems!

However, the real advantage is mental workload.
To get the matrix-vector product to get the fluid velocity, you can either do the inefficient method of calling the function above and then calling ~dot~, or writing a whole separate function to do things the algorithmically most efficient way.
#+begin_src jupyter-julia
function stokeslet_dot_f(x, f)
    recip_r = inv(norm(x))
    xÃÇ = x * recip_r
    prefactor = recip_r / 8œÄ
    (f .+ xÃÇ.*(xÃÇ‚ãÖf)) .* prefactor
end
let f = normalize(rand(SVector{3}))
    x = rand(SVector{3})
    @btime stokeslet2($x) * $f  # Less efficient
    @btime stokeslet_dot_f($x, $f)
end
#+end_src

If we include third order tensors (e.g. stresslets), the ergonomic advantages of ~MultilinearForms~ are significantly more apparent.

#+begin_src jupyter-julia :results silent
function stresslet(x)
    recip_r = inv(norm(x))
    _8œÄ = convert(eltype(x), 8) * œÄ
    radial_fn = recip_r^2 / _8œÄ
    nÃÇ = x * recip_r
    angular_fn = MultilinearForm{3,3}((e1, e2, e3) ->
        3*(nÃÇ‚ãÖe1)*(nÃÇ‚ãÖe2)*(nÃÇ‚ãÖe3) + (e1‚ãÖe2)*(nÃÇ‚ãÖe3) - (e3‚ãÖe1)*(nÃÇ‚ãÖe2) - (e2‚ãÖe3)*(nÃÇ‚ãÖe1))
    return MultilinearForm{3,3}((e1, e2, e3) -> radial_fn * angular_fn(e1, e2, e3))
end
#+end_src

#+begin_src jupyter-julia
@btime SArray(stresslet(x)(:,n,f)) setup=begin
    f = normalize(SVector(1,1,0))
    x = SVector(1.,2,3)
    n = eÃÇ{3}(1)
end
#+end_src

/Note:/ speed depends somewhat on order of arguments ~n~ and ~f~. It would be cool to someday have something that optimized loop ordering.  (Though maybe that should be left to the compiler.)

#+begin_src jupyter-julia
function sourcesink(x)
    recip_r = inv(norm(x))
    _4œÄ = convert(eltype(x), 4) * œÄ
    radial_fn = recip_r^3 / _4œÄ
    nÃÇ = x * recip_r
    angular_fn = MultilinearForm{2,3}((e1, e2) -> 3*(nÃÇ‚ãÖe1)*(nÃÇ‚ãÖe2) - (e1‚ãÖe2))
    return MultilinearForm{2,3}((e1, e2) -> radial_fn * angular_fn(e1, e2))
end

function sourcesink(x, Œµ)
    recip_r = inv(‚àö(x‚ãÖx + Œµ*Œµ))
    _4œÄ = convert(eltype(x), 4) * œÄ
    radial_fn = recip_r^3 / _4œÄ
    nÃÇ = x * recip_r
    angular_fn = MultilinearForm{2,3}((e1, e2) -> 3*(nÃÇ‚ãÖe1)*(nÃÇ‚ãÖe2) - (e1‚ãÖe2))
    return MultilinearForm{2,3}((e1, e2) -> radial_fn * angular_fn(e1, e2))
end
#+end_src

** Evaluation at multiple points

Stokeslet/stresslet at many points:
#+begin_src jupyter-julia
let n = 10000
    xs = rand(SVector{3,Float64}, n)
    xs_grid = (SVector{3,Float64}(x,y,0) for x in LinRange(-1, 1, 100), y in LinRange(-1, 1, 100))
    fs = rand(SVector{3,Float64}, n)

    ElT_mat = typeof(SArray(stokeslet(first(xs))))
    ElT_vec = typeof(SArray(stokeslet(first(xs))(:, first(fs))))
    buf_mat = Vector{ElT_mat}(undef, n)
    buf_vec = Vector{ElT_vec}(undef, n)
    # buf = @btime Vector{$ElT}(undef, $n)  # alloc time is ~500-600ns

    # Inlining is important here!
    @inline fun(x) = SArray(stokeslet(x))
    @inline fun(x,f) = SArray(stokeslet(x)(:,f))

    @btime SArray(stokeslet(first($xs)))                 # one evaluation
    @btime map!($fun, $buf_mat, $xs)                     # many evalutations
    @btime SArray(stokeslet(first($xs))(:, first($fs)))  # one evaluation
    @btime map!($fun, $buf_vec, $xs, $fs)                # many evalutations
end
#+end_src

** Visualization

#+begin_src jupyter-julia
using CairoMakie

let sb = StdBasis{3}(Real)
    f = sb[1]
    n = sb[2]

    # Makie needs a function in a rather speficic format.
    velfield(x2d) = let x = SVector(x2d[1], x2d[2], 0.)
        # vel3d = SArray(stokeslet(x)(:,f))
        # vel3d = SArray((stresslet(x)(:,f,n)))
        # vel3d = SArray((stresslet(x)(:,n,f) - stresslet(x)(:,f,n)) / 2)
        # vel3d = SArray((stresslet(x)(:,f,f) + stresslet(x)(:,n,n)) / 2)
        vel3d = SArray(sourcesink(x)(:,f))
        Point2f(vel3d[SOneTo(2)])
    end

    # flowspeed(x2d) = norm(velfield(x2d))

    streamplot(velfield, -3..3, -2..2, axis=(;aspect=DataAspect()))
end
#+end_src

* Complicated example: Stokes plane-boundary images

** Stress-free wall

#+begin_src jupyter-julia

# Multilinear map that reflects a vector through a plane normal to n
reflect(n::AbstractVector) = MultilinearMap{(3,3)}(
    (e,v) -> (e‚ãÖv) - 2(e‚ãÖn)*(n‚ãÖv)  # ùóú - 2 ùêß ‚äó ùêß
)
let e = StdBasis{3}(Real)
    @test materialize(SArray, reflect( normalize(SVector(0,1,0)) )(:, e[2])) == [0,-1,0]
end
let sb = StdBasis{3}(Real)
    function stokeslet_nostress(x, y, f, n)
        y_img = materialize(typeof(y), reflect(n)(:,y))
        f_refl = materialize(typeof(f), reflect(n)(:,f))

        stokeslet(x - y)(:, f) + stokeslet(x - y_img)(:, f_refl)
    end

    n = SVector(0., 1, 0)
    y = n
    f = normalize(SVector(1., 1., 0))

    velfield(x2d) = let x = SVector(x2d[1], x2d[2], 0.)
        materialize(Point3f, stokeslet_nostress(x, y, f, n))[SOneTo(2)]
    end

    (fig,ax,p) = streamplot(velfield, -3..3, -2..2, axis=(;aspect=DataAspect()))
    hlines!(ax, 0; color=:black)
    display(fig)
end
#+end_src

* Stokes plane-wall system

#+begin_src jupyter-julia :results scalar
let ùêû = StdBasis{3}(Real)

    function wall_stokeslet(x, y, f, n)
        f_refl = materialize(typeof(f), reflect(n)(:, f))
        y_refl = materialize(typeof(y), reflect(n)(:, y))

        mmap = stokeslet(x - y)(:, f) -
            stokeslet(x - y_refl)(:, f) +
            2*(n‚ãÖy) * stresslet(x - y_refl)(:, n, f_refl) -
            (n‚ãÖy)^2 * sourcesink(x - y_refl)(:, f_refl)

        materialize(SArray, mmap)
    end

    f = normalize(SVector(rand(), rand(), 0.))  # SVector{3}(ùêû[1])
    n = SVector{3,Float64}(ùêû[2])

    velfield(x2d) = let x = SVector(x2d[1], x2d[2], 0.)
        Point3f( wall_stokeslet(x, n, f, n) )[SOneTo(2)]
    end

    (fig,ax,p) = streamplot(velfield, -3..3, -2..2, axis=(;aspect=DataAspect()))
    # hlines!(ax, 0; color=:black)
    display(fig)
    # wall_stokeslet([1,1,1], n, f, n)
end
#+end_src


* Tests of internals

#+begin_src jupyter-julia
@testset "Sizes" begin
    SA_like_inner = StaticArray{Tuple{3,3}}
    @test MM._size(SA_like_inner) === MM._size(inner)
    @test MM.samesize(SA_like_inner, inner) === Arr.size(inner) ==
        Arr.known_size(SA_like_inner)
    @test_throws DimensionMismatch MM.samesize(skew, SA_like_inner)
end;

@testset "Output types" begin
    e = StdBasis{3}(Real)
    v = rand(SVector{3,Float64})
    @test eltype(inner(:,v)) == typeof(first(inner(:,v)))
    # TODO: repeat for other types?
end;
#+end_src

* Directions for development

** Special multilinear maps: Kronecker delta and Levi-Civita symbol
** Reshaping dimensions (changing the number of arguments)
This is like changing the tensor product basis to another of compatible length
** Permuting dimensions (changing the order of arguments)
** Composition? Could you pass a MultilinearMap as an argument to another multilinear map?  What should happen?
Say a map that takes a vector and produces a reflection of it through a plane...


* COMMENT
#  LocalWords:  multilinear bilinear
